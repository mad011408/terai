# Model Configuration
# AI Terminal Agent - Model Definitions

# API Configuration
api:
  default_host: "https://go.trybons.ai"
  default_path: "https://go.trybons.ai/v1/chat/completions"
  timeout: 1600
  retry_attempts: 3
  retry_delay: 1.0

# Available Models
models:
  # Anthropic Models
  anthropic/claude-sonnet-4:
    provider: anthropic
    display_name: Claude Sonnet 4
    description: Fast and capable model for general tasks
    max_tokens: 120000
    context_window: 200000
    supports_streaming: true
    supports_functions: true
    supports_vision: true
    cost_per_1k_input: 0.003
    cost_per_1k_output: 0.015

  anthropic/claude-opus-4.1:
    provider: anthropic
    display_name: Claude Opus 4.1
    description: Most capable model for complex reasoning
    max_tokens: 120000
    context_window: 200000
    supports_streaming: true
    supports_functions: true
    supports_vision: true
    cost_per_1k_input: 0.015
    cost_per_1k_output: 0.075

  claude-opus-4-1-20250805:
    provider: anthropic
    display_name: Claude Opus 4.1 (2025-08-05)
    description: Claude Opus 4.1 snapshot from August 2025
    max_tokens: 120000
    context_window: 200000
    supports_streaming: true
    supports_functions: true
    supports_vision: true
    cost_per_1k_input: 0.015
    cost_per_1k_output: 0.075

  anthropic.claude-opus-4-1-20250805-v1:0:
    provider: anthropic
    display_name: Claude Opus 4.1 Bedrock (v1.0)
    description: Claude Opus 4.1 for AWS Bedrock
    max_tokens: 120000
    context_window: 200000
    supports_streaming: true
    supports_functions: true
    supports_vision: true
    cost_per_1k_input: 0.015
    cost_per_1k_output: 0.075

  anthropic/claude-sonnet-4.5:
    provider: anthropic
    display_name: Claude Sonnet 4.5
    description: Enhanced sonnet model
    max_tokens: 120000
    context_window: 200000
    supports_streaming: true
    supports_functions: true
    supports_vision: true

  anthropic/claude-opus-4.5:
    provider: anthropic
    display_name: Claude Opus 4.5
    description: Enhanced opus model
    max_tokens: 120000
    context_window: 200000
    supports_streaming: true
    supports_functions: true
    supports_vision: true

  anthropic/claude-opus-5.0:
    provider: anthropic
    display_name: Claude Opus 5.0
    description: Latest opus model
    max_tokens: 120000
    context_window: 500000
    supports_streaming: true
    supports_functions: true
    supports_vision: true

  anthropic/claude-opus-1.0:
    provider: anthropic
    display_name: Claude Opus 1.0
    description: Original opus model
    max_tokens: 120000
    context_window: 100000
    supports_streaming: true
    supports_functions: true

  claude-opus-4-5-20250929-thinking-32k:
    provider: anthropic
    display_name: Claude Opus 4.5 Thinking
    description: Opus with extended thinking
    max_tokens: 120000
    context_window: 200000
    supports_streaming: true
    supports_functions: true
    supports_thinking: true

  # OpenAI Models
  openai/gpt-5-codex:
    provider: openai
    display_name: GPT-5 Codex
    description: Specialized for code generation
    max_tokens: 120000
    context_window: 128000
    supports_streaming: true
    supports_functions: true
    cost_per_1k_input: 0.01
    cost_per_1k_output: 0.03

  openai/gpt-5.1-codex-max:
    provider: openai
    display_name: GPT-5.1 Codex Max
    description: Enhanced code generation model
    max_tokens: 120000
    context_window: 256000
    supports_streaming: true
    supports_functions: true

  gpt-5.1-2025-11-13:
    provider: openai
    display_name: GPT-5.1 (2025-11-13)
    description: Latest GPT-5.1 snapshot
    max_tokens: 120000
    context_window: 256000
    supports_streaming: true
    supports_functions: true
    supports_vision: true

  # OpenAI O-Series
  o3:
    provider: openai
    display_name: O3
    description: Advanced reasoning model
    max_tokens: 120000
    context_window: 128000
    supports_streaming: true
    supports_functions: true
    supports_reasoning: true

  o4:
    provider: openai
    display_name: O4
    description: Next-gen reasoning model
    max_tokens: 120000
    context_window: 256000
    supports_streaming: true
    supports_functions: true
    supports_reasoning: true

  o5:
    provider: openai
    display_name: O5
    description: Latest reasoning model
    max_tokens: 120000
    context_window: 500000
    supports_streaming: true
    supports_functions: true
    supports_reasoning: true

  # Google Models
  gemini-3-pro:
    provider: google
    display_name: Gemini 3 Pro
    description: Google's advanced multimodal model
    max_tokens: 120000
    context_window: 1000000
    supports_streaming: true
    supports_functions: true
    supports_vision: true

  # xAI Models
  grok-4.1-thinking:
    provider: xai
    display_name: Grok 4.1 Thinking
    description: xAI's reasoning model
    max_tokens: 120000
    context_window: 128000
    supports_streaming: true
    supports_functions: true
    supports_thinking: true

  # Mistral Models
  mistral-large-3:675b-cloud:
    provider: mistral
    display_name: Mistral Large 3 (675B)
    description: Mistral's largest cloud model
    max_tokens: 120000
    context_window: 256000
    supports_streaming: true
    supports_functions: true

  # Other Models
  z-ai/glm-4.6:
    provider: zhipu
    display_name: GLM-4.6 (Free)
    description: Free tier model
    max_tokens: 120000
    context_window: 128000
    supports_streaming: true
    free_tier: true

  sora-2-pro:
    provider: openai
    display_name: Sora 2 Pro
    description: Video generation model
    max_tokens: 120000
    context_window: 32000
    supports_video: true

  # Local Models (Ollama)
  ollama/kimi-k2-thinking:
    provider: ollama
    display_name: Kimi K2 Thinking (Local)
    description: Local thinking model via Ollama
    max_tokens: 120000
    context_window: 32000
    supports_streaming: true
    local: true
    ollama_command: "ollama run kimi-k2-thinking:cloud"

# Model Groups
groups:
  coding:
    - openai/gpt-5-codex
    - openai/gpt-5.1-codex-max
    - anthropic/claude-sonnet-4
  reasoning:
    - o3
    - o4
    - o5
    - claude-opus-4-5-20250929-thinking-32k
    - grok-4.1-thinking
  general:
    - anthropic/claude-sonnet-4
    - anthropic/claude-opus-4.1
    - gemini-3-pro
  free:
    - z-ai/glm-4.6
  local:
    - ollama/kimi-k2-thinking

# Default Settings
defaults:
  model: anthropic/claude-sonnet-4
  temperature: 0.7
  max_tokens: 120000
  top_p: 1.0
  frequency_penalty: 0.0
  presence_penalty: 0.0
  timeout: 1600

# Fallback Configuration
fallback:
  enabled: true
  models:
    - anthropic/claude-sonnet-4
    - openai/gpt-5-codex
    - gemini-3-pro
    - z-ai/glm-4.6
  max_retries: 3
  timeout: 1600
